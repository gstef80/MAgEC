{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import psycopg2\n",
    "import os \n",
    "import random\n",
    "import datetime\n",
    "from sqlalchemy import create_engine\n",
    "import mimic_utils as mimic\n",
    "import magec_utils as mg\n",
    "import matplotlib.pyplot as plt\n",
    "from adjustText import adjust_text\n",
    "\n",
    "pd.set_option('display.max_columns', None)\n",
    "\n",
    "random.seed(22891)\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_magecs(p=None, models=('lr', 'mlp', 'svm', 'lstm')):\n",
    "    prefix = 'magec_'\n",
    "    postfix = '_0.csv' if p is None else '_p' + str(p) + '.csv'\n",
    "    magecs = []\n",
    "    for m in models:\n",
    "        filename = prefix + m + postfix\n",
    "        magecs.append(pd.read_csv(filename))\n",
    "    return magecs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "vitals = ['heartrate_mean', 'sysbp_mean', 'diasbp_mean', 'meanbp_mean',\n",
    "          'resprate_mean', 'tempc_mean', 'spo2_mean', 'glucose_mean']\n",
    "\n",
    "labs = ['aniongap', 'albumin', 'bicarbonate', 'bilirubin', 'creatinine', \n",
    "        'chloride', 'glucose', 'hemoglobin', 'lactate', \n",
    "        'magnesium', 'phosphate', 'platelet', 'potassium', 'ptt', 'inr', \n",
    "        'pt', 'sodium', 'bun', 'wbc']  # -hematocrit\n",
    "\n",
    "comobs = ['congestive_heart_failure', 'chronic_pulmonary', 'pulmonary_circulation']\n",
    "\n",
    "others = ['age', 'gender']\n",
    "\n",
    "features = vitals+labs\n",
    "\n",
    "df_cohort = mimic.get_mimic_data()\n",
    "\n",
    "df_ml = mimic.get_ml_data(df_cohort)\n",
    "\n",
    "df_time = mimic.get_ml_series_data(df_cohort)\n",
    "\n",
    "_, _, _, _, _, _, Y_validation = mimic.train_valid_ml(df_ml)\n",
    "\n",
    "stsc2, series_means, _, df_series_valid, _, _, xt_valid, Yt_valid = mimic.train_valid_series(df_time, Y_validation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_notes = mimic.get_cohort_notes()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "magecs = get_magecs()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_magec_cols = list(set(df_series_valid.columns) - {'label'})\n",
    "x_magec = df_series_valid[x_magec_cols]\n",
    "y_magec = df_series_valid['label']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "joined = mg.magec_models(*magecs, Xdata=x_magec, Ydata=y_magec, features=features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def most_abnormal(x, features):\n",
    "    res = None\n",
    "    feat = None\n",
    "    for f in features:\n",
    "        if res is None or abs(x[f]) > res:\n",
    "            res = abs(x[f])\n",
    "            feat = f\n",
    "    return feat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-9-9a6e1ec27d61>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      3\u001b[0m                                        'orig_prob_svm', 'orig_prob_lstm']].apply(np.mean, 1)\n\u001b[1;32m      4\u001b[0m joined[['best_feat', 'new_risk', 'rank_feat', 'rank_val']] = joined.apply(\n\u001b[0;32m----> 5\u001b[0;31m     lambda x: mimic.best_feature(x, prob_cols), axis=1)\n\u001b[0m\u001b[1;32m      6\u001b[0m \u001b[0mjoined\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'most_abnormal'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mjoined\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mlambda\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mmost_abnormal\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeatures\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/magec/lib/python3.7/site-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36mapply\u001b[0;34m(self, func, axis, broadcast, raw, reduce, result_type, args, **kwds)\u001b[0m\n\u001b[1;32m   6926\u001b[0m             \u001b[0mkwds\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   6927\u001b[0m         )\n\u001b[0;32m-> 6928\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mop\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_result\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   6929\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   6930\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mapplymap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/magec/lib/python3.7/site-packages/pandas/core/apply.py\u001b[0m in \u001b[0;36mget_result\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    184\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply_raw\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    185\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 186\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply_standard\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    187\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    188\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mapply_empty_result\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/magec/lib/python3.7/site-packages/pandas/core/apply.py\u001b[0m in \u001b[0;36mapply_standard\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    290\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    291\u001b[0m         \u001b[0;31m# compute the result using the series generator\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 292\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply_series_generator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    293\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    294\u001b[0m         \u001b[0;31m# wrap results\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/magec/lib/python3.7/site-packages/pandas/core/apply.py\u001b[0m in \u001b[0;36mapply_series_generator\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    319\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    320\u001b[0m                 \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mv\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mseries_gen\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 321\u001b[0;31m                     \u001b[0mresults\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mv\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    322\u001b[0m                     \u001b[0mkeys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    323\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-9-9a6e1ec27d61>\u001b[0m in \u001b[0;36m<lambda>\u001b[0;34m(x)\u001b[0m\n\u001b[1;32m      3\u001b[0m                                        'orig_prob_svm', 'orig_prob_lstm']].apply(np.mean, 1)\n\u001b[1;32m      4\u001b[0m joined[['best_feat', 'new_risk', 'rank_feat', 'rank_val']] = joined.apply(\n\u001b[0;32m----> 5\u001b[0;31m     lambda x: mimic.best_feature(x, prob_cols), axis=1)\n\u001b[0m\u001b[1;32m      6\u001b[0m \u001b[0mjoined\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'most_abnormal'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mjoined\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mlambda\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mmost_abnormal\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeatures\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/notebook/MAgEC/mimic_utils.py\u001b[0m in \u001b[0;36mbest_feature\u001b[0;34m(data, cols, feat)\u001b[0m\n\u001b[1;32m    474\u001b[0m             \u001b[0morig\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'orig_prob_'\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    475\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mmagec\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdata\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mperturb\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdata\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0morig\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 476\u001b[0;31m                 \u001b[0mperturb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mperturb\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    477\u001b[0m                 \u001b[0morig\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0morig\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    478\u001b[0m                 \u001b[0mfeat_risks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mperturb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/magec/lib/python3.7/site-packages/pandas/core/series.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   1069\u001b[0m         \u001b[0mkey\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcom\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply_if_callable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1070\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1071\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_value\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1072\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1073\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mis_scalar\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/magec/lib/python3.7/site-packages/pandas/core/indexes/base.py\u001b[0m in \u001b[0;36mget_value\u001b[0;34m(self, series, key)\u001b[0m\n\u001b[1;32m   4728\u001b[0m         \u001b[0mk\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_convert_scalar_indexer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkind\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"getitem\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4729\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 4730\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_value\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mk\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtz\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mseries\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"tz\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   4731\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4732\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mholds_integer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_boolean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/magec/lib/python3.7/site-packages/pandas/core/series.py\u001b[0m in \u001b[0;36mdtype\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    473\u001b[0m         \u001b[0mReturn\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mdtype\u001b[0m \u001b[0mobject\u001b[0m \u001b[0mof\u001b[0m \u001b[0mthe\u001b[0m \u001b[0munderlying\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    474\u001b[0m         \"\"\"\n\u001b[0;32m--> 475\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_data\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    476\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    477\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/magec/lib/python3.7/site-packages/pandas/core/internals/managers.py\u001b[0m in \u001b[0;36mdtype\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1558\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1559\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1560\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_block\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1561\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1562\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/magec/lib/python3.7/site-packages/pandas/core/internals/blocks.py\u001b[0m in \u001b[0;36mdtype\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    343\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    344\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 345\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    346\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    347\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "prob_cols = [c for c in joined.columns if c.startswith('perturb')]\n",
    "joined['orig_prob_ensemble'] = joined[['orig_prob_mlp', 'orig_prob_lr', \n",
    "                                       'orig_prob_svm', 'orig_prob_lstm']].apply(np.mean, 1)\n",
    "joined[['best_feat', 'new_risk', 'rank_feat', 'rank_val']] = joined.apply(\n",
    "    lambda x: mimic.best_feature(x, prob_cols), axis=1)\n",
    "joined['most_abnormal'] = joined.apply(lambda x: most_abnormal(x, features), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "drivers = ['heartrate_mean', 'sysbp_mean', 'diasbp_mean', \n",
    "           'meanbp_mean', 'resprate_mean', 'spo2_mean']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "joined[drivers+['most_abnormal','best_feat', 'rank_feat', 'rank_val']].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.sum(joined['best_feat'] != joined['rank_feat']) / len(joined)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def expected(x, drivers, sigmas=0.5, threshold=0.5):\n",
    "    orig_prob_ensemble = x['orig_prob_ensemble']\n",
    "    best_feat = x['best_feat']\n",
    "    label = x['label']\n",
    "    # some predicates\n",
    "    cond1 = orig_prob_ensemble > threshold  # models predict MV (ventilated)\n",
    "    cond2 = np.all(abs(x[drivers]) <= sigmas)  # all drivers are 'normal'\n",
    "    cond3 = np.isin(best_feat, drivers)  # MAgEC 'best feature' is a driver\n",
    "    cond4 = x[best_feat] > sigmas # MAgEC 'best feature' is 'abnormal'\n",
    "    cond5 = label == 1  # patient was ventilated\n",
    "    # Unexpected (ventilated):\n",
    "    # 1. ensemble_probability greater than 0.5, \n",
    "    # 2. all drivers are normal\n",
    "    # 3. best feature is not a driver \n",
    "    # 4. patient was ventillated\n",
    "    if cond1 and cond2 and (not cond3) and cond5:\n",
    "        return 'unexpected_ventilated_nondriver'\n",
    "    elif cond1 and cond2 and cond3 and cond5:\n",
    "        return 'unexpected_ventilated_driver'\n",
    "    # Missed Unexpected (ventilated)\n",
    "    elif (not cond1) and cond2 and cond5:\n",
    "        return 'missed_unexpected_ventilated'\n",
    "    # Expected (ventilated): \n",
    "    # 1. one or more drivers were abnormal\n",
    "    # 2. patient was ventillated\n",
    "    elif cond1 and (not cond2) and (not cond3) and cond5:\n",
    "        return 'expected_ventilated_nondriver'\n",
    "    elif cond1 and (not cond2) and cond3 and cond5:\n",
    "        return 'expected_ventilated_driver'\n",
    "    elif (not cond1) and (not cond2) and cond5:\n",
    "        return 'missed_expected_ventilated'\n",
    "    # Other (ventilated)\n",
    "    elif cond5:\n",
    "        return 'other_ventilated'\n",
    "    # Unexpected (not ventilated)\n",
    "    # 1. ensemble_probability less than 0.5\n",
    "    # 2. one or more drivers are abnormal\n",
    "    # 3. patient was not ventilated\n",
    "    elif (not cond1) and (not cond2) and (not cond5):\n",
    "        return 'unexpected_notventilated'\n",
    "    # Expected (not ventilated)\n",
    "    # 1. ensemble_probability less than 0.5\n",
    "    # 2. all drivers are normal\n",
    "    # 3. patient was not ventilated\n",
    "    elif (not cond1) and cond2 and (not cond5):\n",
    "        return 'expected_notventilated'\n",
    "    elif (not cond5):\n",
    "        return 'other_notventilated'\n",
    "    else:\n",
    "        return 'other'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "joined['stats'] = joined.apply(lambda x: expected(x, drivers), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "unexpected_notventilated           32871\n",
       "missed_expected_ventilated          4064\n",
       "other_notventilated                 2130\n",
       "expected_ventilated_driver           880\n",
       "expected_notventilated               485\n",
       "expected_ventilated_nondriver        304\n",
       "unexpected_ventilated_nondriver      232\n",
       "missed_unexpected_ventilated          62\n",
       "unexpected_ventilated_driver           1\n",
       "Name: stats, dtype: int64"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "joined['stats'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(41029, 32944)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "excluded = set(df_cohort[np.all(np.isnan(df_cohort[drivers]), axis=1)].subject_id.unique())\n",
    "filtered = joined[~np.isin(joined.case, list(excluded))]\n",
    "len(joined), len(filtered)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2083, 1557)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "joined.case.nunique(), filtered.case.nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filtered['stats'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Unexpected Ventilated Classes (normal drivers w/ MV=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "missed_unexpected_ventilated = set(filtered[filtered['stats'] == 'missed_unexpected_ventilated'].case.unique())\n",
    "unexpected_ventilated_nondriver = set(filtered[filtered['stats'] == 'unexpected_ventilated_nondriver'].case.unique())\n",
    "unexpected_ventilated_driver = set(filtered[filtered['stats'] == 'unexpected_ventilated_driver'].case.unique())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### There were 8 patients that MAgEC correctly identified as ventilated that had all drivers 'normal' and 18 such patients that MAgEC missed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(missed_unexpected_ventilated), len(unexpected_ventilated_nondriver), len(unexpected_ventilated_driver)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### There are 2 cases missed that were correctly identified at different time points in their trajectories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "missed_unexpected_ventilated.intersection(unexpected_ventilated_nondriver.union(unexpected_ventilated_driver))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Expected Ventilated Classes (one or more abnormal driver w/ MV=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "missed_expected_ventilated = set(filtered[filtered['stats'] == 'missed_expected_ventilated'].case.unique())\n",
    "expected_ventilated_nondriver = set(filtered[filtered['stats'] == 'expected_ventilated_nondriver'].case.unique())\n",
    "expected_ventilated_driver = set(filtered[filtered['stats'] == 'expected_ventilated_driver'].case.unique())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### There were 186 patients that MAgEC missed, but 93 of them were identitied at some point in their trajectories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(missed_expected_ventilated), len(expected_ventilated_nondriver), len(expected_ventilated_driver)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(missed_expected_ventilated.intersection(expected_ventilated_nondriver.union(expected_ventilated_driver)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(missed_expected_ventilated.union(expected_ventilated_nondriver).\\\n",
    "    union(expected_ventilated_driver).union(missed_unexpected_ventilated).\\\n",
    "    union(unexpected_ventilated_nondriver).union(unexpected_ventilated_driver))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filtered[filtered.label==1].case.nunique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "unexpected_ventilated_nondriver.union(unexpected_ventilated_driver)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "missed_unexpected_ventilated - unexpected_ventilated_nondriver.union(unexpected_ventilated_driver)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "index = 1000\n",
    "joined[joined.case == index][drivers+['timepoint','orig_prob_ensemble',\n",
    "                                      'best_feat','new_risk', 'rank_feat', 'rank_val', 'stats','label']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x1 = filtered[filtered.label == 1]['orig_prob_lstm']\n",
    "x2 = filtered[filtered.label == 0]['orig_prob_lstm']\n",
    "bins = np.linspace(0, 1, 100)\n",
    "plt.figure(figsize=[10,8])\n",
    "plt.hist(x1, bins, alpha=0.5, label='ventilated', density=False)\n",
    "plt.hist(x2, bins, alpha=0.5, label='not ventilated', density=False)\n",
    "plt.legend(loc='upper right');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mort = df_cohort[['subject_id', 'mort_icu']].drop_duplicates()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(mort), df_cohort.subject_id.nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stats = joined.merge(mort, left_on='case', right_on='subject_id', how='inner')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stats[['case','stats']].groupby('stats')['case'].nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stats[['case','stats','mort_icu']].groupby(['stats','mort_icu'])['case'].nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stats[(stats['stats'] == 'unexpected_ventilated')&(stats['mort_icu']==1)]['case'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mimic.print_notes(df_notes, 32505)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "unexpected_ventilated_nondriver"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "joined[joined.case == 44775][drivers+['timepoint','orig_prob_ensemble','stats','label','best_feat','new_risk']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_cohort[df_cohort.subject_id==1000][drivers]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "excluded = set(df_cohort[np.all(np.isnan(df_cohort[drivers]), axis=1)].subject_id.unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "joined[~np.isin(joined.case, list(excluded))].case.nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "category = 'unexpexted_ventilated'\n",
    "case = 1000\n",
    "\n",
    "foo[(foo['stats'] == category)&(foo['mort_icu']==1)&(foo['case']==case)][drivers+\n",
    "                                                                         ['orig_prob_ensemble',\n",
    "                                                                          'most_abnormal',\n",
    "                                                                          'best_feat',\n",
    "                                                                          'label', \n",
    "                                                                          'new_risk']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "foo[foo['case']==1000]['case']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(foo), len(joined)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "foo[foo['case']==1000][drivers+['orig_prob_ensemble','most_abnormal','best_feat','label', 'new_risk','phosphate']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "12/143, 43/1645"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_cohort[df_cohort.subject_id == 1000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "foo[foo['case']==1000][drivers+['orig_prob_ensemble','most_abnormal','best_feat','label', 'new_risk','phosphate']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mimic.print_notes(df_notes, 1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def transitions(joined):\n",
    "    group = joined[['case','timepoint','stats']].groupby('case')['timepoint','stats']\n",
    "    transitions = dict()\n",
    "    for case, x in group:\n",
    "        times = x['timepoint']\n",
    "        stats = x['stats']\n",
    "        sorter = np.argsort(times)[::-1]  # larger value is earliest timepoint\n",
    "        stats = np.array(stats)[sorter]\n",
    "        if len(stats) > 0:\n",
    "            prev = 0\n",
    "            for i in range(1, len(stats)):\n",
    "                t0 = stats[prev]\n",
    "                t1 = stats[i]\n",
    "                if (t0, t1) in transitions:\n",
    "                    transitions[(t0,t1)] += 1\n",
    "                else:\n",
    "                    transitions[(t0,t1)] = 1\n",
    "                prev = i\n",
    "    return transitions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tran_dict = transitions(joined)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tran_df = pd.DataFrame.from_dict(tran_dict, orient='index').reset_index()\n",
    "tran_df.columns = ['transition', 'counts']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tran_df.sort_values('counts', ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "joined['case'].nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.all(abs(joined.iloc[1][drivers]) < 0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "joined.iloc[1][drivers]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def anomalies(x, drivers, sigmas=0.5, threshold=0.5):\n",
    "    orig_prob_ensemble = x['orig_prob_ensemble']\n",
    "    if orig_prob_ensemble < threshold:\n",
    "        return False\n",
    "    else:\n",
    "        for driver in drivers:\n",
    "            if abs(x[driver]) > sigmas:\n",
    "                return False\n",
    "    return True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "joined['anomaly'] = joined.apply(lambda x: anomalies(x, drivers), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.sum(joined['anomaly'] == True), np.sum(joined['anomaly'] == False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "joined[(joined['anomaly'] == False) & \n",
    "       (np.isin(joined['best_feat'], drivers))][drivers+['best_feat']].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "joined[(joined['label'] == 1) & \n",
    "       (np.isin(joined['best_feat'], drivers)) & \n",
    "       (abs(joined[joined['best_feat']]) < 0.5)\n",
    "       ][drivers+['orig_prob_ensemble',\n",
    "                                         'most_abnormal',\n",
    "                                         'best_feat', \n",
    "                                         'new_risk',\n",
    "                                         'label']].sort_values(['orig_prob_ensemble'], ascending=False).head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "joined[joined['anomaly'] == True][features+['orig_prob_ensemble','most_abnormal','best_feat','label']].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "joined[(joined['anomaly'] == True) & (joined['label'] == 1)]['case'].nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(joined[(joined['anomaly'] == True) & (joined['label'] == 1)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "joined[(joined['anomaly'] == True) & \n",
    "       (joined['label'] == 1)].best_feat.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "joined[(joined['anomaly'] == True) & \n",
    "       (joined['label'] == 1) & \n",
    "       (np.isin(joined['best_feat'], drivers))][drivers+['orig_prob_ensemble',\n",
    "                                         'most_abnormal',\n",
    "                                         'best_feat', \n",
    "                                         'new_risk',\n",
    "                                         'label']].sort_values(['orig_prob_ensemble'], ascending=False).head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "joined[(joined['anomaly'] == True) & \n",
    "       (joined['label'] == 1)][drivers+['orig_prob_ensemble',\n",
    "                                         'most_abnormal',\n",
    "                                         'best_feat',\n",
    "                                        'new_risk',\n",
    "                                         'label']].sort_values(['orig_prob_ensemble'], ascending=False).head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "joined[(joined['anomaly'] == True) & \n",
    "       (joined['label'] == 1)][drivers+['orig_prob_ensemble',\n",
    "                                        'most_abnormal',\n",
    "                                        'best_feat', \n",
    "                                        'new_risk',\n",
    "                                        'label']].sort_values(['new_risk']).head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "index = 37836\n",
    "case = joined.loc[index].case\n",
    "timepoint = joined.loc[268].timepoint\n",
    "best_feat = joined.loc[index].best_feat\n",
    "abnormal = joined.loc[index].most_abnormal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_cohort[(df_cohort.subject_id==case) & (df_cohort.timepoint==timepoint)][[best_feat, abnormal]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mimic.print_notes(df_notes, case)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mimic.print_notes?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "joined[(joined['anomaly'] == True) & \n",
    "       (joined['label'] == 1)]['abnormal'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "joined[(joined['anomaly'] == True) & \n",
    "       (joined['label'] == 1)]['best_feat'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_notes = mimic.get_cohort_notes()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Scratchpad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rbos = pd.read_json('mimic_rbos_valid.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rbos[['lstm_lr', 'mlp_lr', 'mlp_lstm', 'rf_lr', 'rf_lstm', 'rf_mlp']].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rbos[['lstm_lr', 'mlp_lr', 'mlp_lstm', 'rf_lr', 'rf_lstm', 'rf_mlp']].std()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "joined = pd.read_csv('time_mimic_magecs.csv')\n",
    "prob_cols = [c for c in joined.columns if c.startswith('perturb') and 'resprate_mean' not in c]\n",
    "joined[['best_feat', 'new_risk']] = joined.apply(lambda x: mimic.best_feature(x, prob_cols), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "joined['orig_prob_ensemble'] = joined[['orig_prob_mlp', 'orig_prob_lr', \n",
    "                                       'orig_prob_rf', 'orig_prob_lstm']].apply(np.mean, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vitals = ['heartrate_mean', 'sysbp_mean', 'diasbp_mean', 'meanbp_mean',\n",
    "          'resprate_mean', 'tempc_mean', 'spo2_mean', 'glucose_mean']\n",
    "\n",
    "labs = ['aniongap', 'albumin', 'bicarbonate', 'bilirubin', 'creatinine', \n",
    "        'chloride', 'glucose', 'hemoglobin', 'lactate', \n",
    "        'magnesium', 'phosphate', 'platelet', 'potassium', 'ptt', 'inr', \n",
    "        'pt', 'sodium', 'bun', 'wbc']  # -hematocrit\n",
    "\n",
    "comobs = ['congestive_heart_failure', 'chronic_pulmonary', 'pulmonary_circulation']\n",
    "\n",
    "others = ['age', 'gender']\n",
    "\n",
    "features = vitals+labs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def most_abnormal(x, features):\n",
    "    res = None\n",
    "    feat = None\n",
    "    for f in features:\n",
    "        if f == 'resprate_mean':\n",
    "            continue\n",
    "        if res is None or abs(x[f]) > res:\n",
    "            res = abs(x[f])\n",
    "            feat = f\n",
    "    return feat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "joined['abnormal'] = joined.apply(lambda x: most_abnormal(x, features), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "joined[features+['abnormal','best_feat']].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.sum(joined.best_feat=='resprate_mean'), np.sum(joined.abnormal=='resprate_mean')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.sum(joined['abnormal'] == joined['best_feat']), np.sum(joined['abnormal'] != joined['best_feat'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "7736 / (7736+33293), (7736+33293) == len(joined)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(joined) == 8310 + 32719"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "8310 / len(joined)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(np.sum((joined.new_risk < 0.5) & \n",
    "             (joined.best_feat != 'resprate_mean') & \n",
    "             (joined.abnormal != 'resprate_mean')\n",
    "             (joined.orig_prob_ensemble > 0.5)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(np.sum((joined.new_risk < 0.5) & \n",
    "             (joined.best_feat != 'resprate_mean') & \n",
    "             (joined.orig_prob_ensemble > 0.5) & \n",
    "             (joined.abnormal != joined.best_feat)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "906 / 1425"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(np.sum((joined.label==1)& (joined.orig_prob_ensemble > 0.5))) \n",
    "print(np.sum((joined.label==1) & \n",
    "             (joined.new_risk < 0.5) & \n",
    "             (joined.best_feat != 'resprate_mean') & \n",
    "             (joined.orig_prob_ensemble > 0.5)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "554 / 1540"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "joined[joined.label == 1]['best_feat'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "index = 31760\n",
    "fig1, ax1 = mimic.best_feat_plot(joined, df_cohort, index, title='for Mean Arterial Pressure');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "joined.loc[index][['case','timepoint','abnormal','best_feat','orig_prob_ensemble']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_series_valid.loc[joined.loc[index]['case'], joined.loc[index]['timepoint']].sort_values()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "index = 10406\n",
    "fig2, ax2 = mimic.best_feat_plot(joined, df_cohort, index, title='for Mean Arterial Pressure');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "joined.loc[index][['case','timepoint','abnormal','best_feat','orig_prob_ensemble']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "joined[(joined.case==15396) & \n",
    "       (joined.timepoint==11)][['case','timepoint','abnormal','best_feat','orig_prob_ensemble']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_cohort[(df_cohort.subject_id==joined.loc[index]['case']) & \n",
    "          (df_cohort.timepoint==11)][features]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "series_means['sysbp_mean']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_series_valid.loc[joined.loc[index]['case'], joined.loc[index]['timepoint']].sort_values()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_time[(df_time.subject_id==joined.loc[index]['case']) & \n",
    "          (df_time.timepoint==joined.loc[index]['timepoint'])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_cohort = mimic.get_mimic_data()\n",
    "\n",
    "df_ml = mimic.get_ml_data(df_cohort)\n",
    "\n",
    "df_time = mimic.get_ml_series_data(df_cohort)\n",
    "\n",
    "_, x_validation, stsc, _, xst_validation, _, Y_validation = mimic.train_valid_ml(df_ml)\n",
    "\n",
    "stsc2, series_means, _, df_series_valid, _, _, xt_valid, Yt_valid = mimic.train_valid_series(df_time, Y_validation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_series_valid.loc[joined.loc[index]['case'], joined.loc[index]['timepoint']].sort_values()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(df_cohort)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vitals = ['heartrate_mean', 'sysbp_mean', 'diasbp_mean', 'meanbp_mean',\n",
    "          'resprate_mean', 'tempc_mean', 'spo2_mean', 'glucose_mean']\n",
    "\n",
    "labs = ['aniongap', 'albumin', 'bicarbonate', 'bilirubin', 'creatinine', \n",
    "        'chloride', 'glucose', 'hemoglobin', 'lactate', \n",
    "        'magnesium', 'phosphate', 'platelet', 'potassium', 'ptt', 'inr', \n",
    "        'pt', 'sodium', 'bun', 'wbc']  # -hematocrit\n",
    "\n",
    "comobs = ['congestive_heart_failure', 'chronic_pulmonary', 'pulmonary_circulation']\n",
    "\n",
    "others = ['age', 'gender']\n",
    "\n",
    "features = vitals+labs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_magecs(p=None, models=('lr', 'mlp', 'svm', 'lstm')):\n",
    "    prefix = 'magec_'\n",
    "    postfix = '_0.csv' if p is None else '_p' + str(p) + '.csv'\n",
    "    magecs = []\n",
    "    for m in models:\n",
    "        filename = prefix + m + postfix\n",
    "        magecs.append(pd.read_csv(filename))\n",
    "    return magecs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_magec_cols = list(set(df_series_valid.columns) - {'label'})\n",
    "x_magec = df_series_valid[x_magec_cols]\n",
    "y_magec = df_series_valid['label']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "magecs = get_magecs()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "joined = mg.magec_models(*magecs, Xdata=x_magec, Ydata=y_magec, features=features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prob_cols = [c for c in joined.columns if c.startswith('perturb')]\n",
    "joined['orig_prob_ensemble'] = joined[['orig_prob_mlp', 'orig_prob_lr', \n",
    "                                       'orig_prob_svm', 'orig_prob_lstm']].apply(np.mean, 1)\n",
    "joined[['best_feat', 'new_risk']] = joined.apply(lambda x: mimic.best_feature(x, prob_cols), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(joined)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "joined.loc[31760]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "index = 31760\n",
    "fig1, ax1 = mimic.best_feat_plot(joined, df_cohort, index, title='for Mean Arterial Pressure');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "timepoint = 14\n",
    "txt = 'Clinical values and ranked MAgECs at time point {}'\n",
    "fig  = mg.panel_plot(xst_validation.columns, features, stsc2, joined, \n",
    "                                                      joined.loc[index].case, timepoint, \n",
    "                     models=('lr','svm','mlp','lstm', 'ensemble'), label='label', limit=6, rotate=25, \n",
    "                  title=txt.format(timepoint))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "index = 10406\n",
    "fig2, ax2 = mimic.best_feat_plot(joined, df_cohort, index, title='for Mean Arterial Pressure');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy import interpolate\n",
    "from adjustText import adjust_text\n",
    "\n",
    "def best_feat_plot(joined, cohort, index, title='', save=False, feat=None):\n",
    "    data = joined.loc[index]\n",
    "    case, t_0, label, orig_prob, new_risk = data[['case', 'timepoint', 'label',\n",
    "                                                  'orig_prob_ensemble', 'new_risk']]\n",
    "    if feat is None:\n",
    "        best_feat = joined.loc[index]['best_feat']\n",
    "    else:\n",
    "        best_feat = feat\n",
    "\n",
    "    xy = cohort[cohort['subject_id'] == case][['timepoint', best_feat]].values\n",
    "    x = [int(x[0]) for x in xy]\n",
    "    yy = [x[1] for x in xy]\n",
    "\n",
    "    fig, ax = plt.subplots(nrows=1, ncols=2, figsize=(16, 6))\n",
    "\n",
    "    mimic.plot_feature(ax[0], x, yy, best_feat, case, label, title=title)\n",
    "\n",
    "    xyzw = joined[joined.case == case][['timepoint', 'orig_prob_ensemble', 'best_feat', 'new_risk']].values\n",
    "    x = [int(x[0]) for x in xyzw]\n",
    "    y = [x[1] for x in xyzw]\n",
    "    z = [x[2] for x in xyzw]\n",
    "    w = [x[3] for x in xyzw]\n",
    "    zz = [cohort[(cohort['subject_id'] == case) & (cohort['timepoint'] == x[i])][feat].values[0]\n",
    "          for i, feat in enumerate(z)]\n",
    "\n",
    "    plot_risk(ax[1], x, y, z, w, zz, case, label, feat=feat)\n",
    "    ax[1].invert_xaxis()\n",
    "\n",
    "    if save:\n",
    "        plt.savefig('case_{}_series.png'.format(case))\n",
    "\n",
    "    return fig, ax\n",
    "\n",
    "def plot_risk(ax, x, y, z, w, yy, case, label, feat=None):\n",
    "    ax.plot(x, y, 'rx--')\n",
    "    ax.plot(np.linspace(ax.get_xlim()[0], ax.get_xlim()[1], 10), 0.5 * np.ones(10), '--')\n",
    "    txt = 'Case {}: Hourly Estimated Ensemble Risk (Outcome: {})'\n",
    "    ax.set_title(txt.format(case, label))\n",
    "    ax.set_ylabel('Ensemble Risk')\n",
    "    ax.set_xlabel('hours to event')\n",
    "    ax.grid('on')\n",
    "    # ax.set_ylim([0.2, 0.9])\n",
    "\n",
    "    texts = []\n",
    "\n",
    "    for i, txt in enumerate(z):\n",
    "        if np.isnan(yy[i]):\n",
    "            continue\n",
    "        if feat is not None and feat == txt:    \n",
    "            msg = txt + ' = {:.2f}\\n perturb. risk = {:.2g}'.format(yy[i], w[i])\n",
    "            texts.append(ax.text(x[i], y[i], msg))\n",
    "        elif feat is None and (w[i] < 0.5 < y[i]):\n",
    "            msg = txt + ' = {:.2f}\\n perturb. risk = {:.2g}'.format(yy[i], w[i])\n",
    "            texts.append(ax.text(x[i], y[i], msg))\n",
    "\n",
    "    if feat is None:\n",
    "        f = interpolate.interp1d(x, y)\n",
    "        x = np.linspace(min(x), max(x), 140)\n",
    "        y = f(x)\n",
    "        adjust_text(texts, x, y, arrowprops=dict(arrowstyle=\"->\", color='b', lw=0.5), autoalign='xy')\n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "index = 10406\n",
    "fig2, ax2 = best_feat_plot(joined, df_cohort, index, title='for Mean Arterial Pressure', feat='meanbp_mean');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
